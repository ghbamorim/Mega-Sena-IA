{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 19.58041958041958,
  "eval_steps": 500,
  "global_step": 2800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.34965034965034963,
      "grad_norm": 0.9351866841316223,
      "learning_rate": 4.965734265734266e-05,
      "loss": 3.2278,
      "step": 50
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 1.243165373802185,
      "learning_rate": 4.930769230769231e-05,
      "loss": 0.9318,
      "step": 100
    },
    {
      "epoch": 1.048951048951049,
      "grad_norm": 1.3447939157485962,
      "learning_rate": 4.895804195804196e-05,
      "loss": 0.5325,
      "step": 150
    },
    {
      "epoch": 1.3986013986013985,
      "grad_norm": 0.9458436369895935,
      "learning_rate": 4.8608391608391615e-05,
      "loss": 0.4572,
      "step": 200
    },
    {
      "epoch": 1.7482517482517483,
      "grad_norm": 1.0815223455429077,
      "learning_rate": 4.825874125874126e-05,
      "loss": 0.4369,
      "step": 250
    },
    {
      "epoch": 2.097902097902098,
      "grad_norm": 1.5342481136322021,
      "learning_rate": 4.790909090909091e-05,
      "loss": 0.4242,
      "step": 300
    },
    {
      "epoch": 2.4475524475524475,
      "grad_norm": 0.9423415064811707,
      "learning_rate": 4.755944055944056e-05,
      "loss": 0.4106,
      "step": 350
    },
    {
      "epoch": 2.797202797202797,
      "grad_norm": 1.1328142881393433,
      "learning_rate": 4.720979020979021e-05,
      "loss": 0.4121,
      "step": 400
    },
    {
      "epoch": 3.1468531468531467,
      "grad_norm": 1.698107123374939,
      "learning_rate": 4.686013986013986e-05,
      "loss": 0.4001,
      "step": 450
    },
    {
      "epoch": 3.4965034965034967,
      "grad_norm": 1.0327985286712646,
      "learning_rate": 4.6510489510489516e-05,
      "loss": 0.3975,
      "step": 500
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 1.0816850662231445,
      "learning_rate": 4.616083916083916e-05,
      "loss": 0.4022,
      "step": 550
    },
    {
      "epoch": 4.195804195804196,
      "grad_norm": 1.198314905166626,
      "learning_rate": 4.581118881118882e-05,
      "loss": 0.3875,
      "step": 600
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 1.0045191049575806,
      "learning_rate": 4.5461538461538464e-05,
      "loss": 0.3889,
      "step": 650
    },
    {
      "epoch": 4.895104895104895,
      "grad_norm": 1.376796007156372,
      "learning_rate": 4.511188811188811e-05,
      "loss": 0.3924,
      "step": 700
    },
    {
      "epoch": 5.244755244755245,
      "grad_norm": 1.3933148384094238,
      "learning_rate": 4.4762237762237764e-05,
      "loss": 0.391,
      "step": 750
    },
    {
      "epoch": 5.594405594405594,
      "grad_norm": 1.1889476776123047,
      "learning_rate": 4.441258741258741e-05,
      "loss": 0.3841,
      "step": 800
    },
    {
      "epoch": 5.944055944055944,
      "grad_norm": 1.3119568824768066,
      "learning_rate": 4.4062937062937064e-05,
      "loss": 0.3894,
      "step": 850
    },
    {
      "epoch": 6.293706293706293,
      "grad_norm": 1.486380696296692,
      "learning_rate": 4.371328671328672e-05,
      "loss": 0.3874,
      "step": 900
    },
    {
      "epoch": 6.643356643356643,
      "grad_norm": 1.640847086906433,
      "learning_rate": 4.3363636363636365e-05,
      "loss": 0.3808,
      "step": 950
    },
    {
      "epoch": 6.993006993006993,
      "grad_norm": 1.2805757522583008,
      "learning_rate": 4.301398601398602e-05,
      "loss": 0.3849,
      "step": 1000
    },
    {
      "epoch": 7.3426573426573425,
      "grad_norm": 1.177901268005371,
      "learning_rate": 4.2664335664335665e-05,
      "loss": 0.3818,
      "step": 1050
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 1.292192816734314,
      "learning_rate": 4.231468531468531e-05,
      "loss": 0.3797,
      "step": 1100
    },
    {
      "epoch": 8.041958041958042,
      "grad_norm": 1.1415562629699707,
      "learning_rate": 4.1965034965034966e-05,
      "loss": 0.3781,
      "step": 1150
    },
    {
      "epoch": 8.391608391608392,
      "grad_norm": 1.2415692806243896,
      "learning_rate": 4.161538461538462e-05,
      "loss": 0.3785,
      "step": 1200
    },
    {
      "epoch": 8.741258741258742,
      "grad_norm": 1.2842239141464233,
      "learning_rate": 4.1265734265734266e-05,
      "loss": 0.3813,
      "step": 1250
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 1.0469402074813843,
      "learning_rate": 4.091608391608392e-05,
      "loss": 0.3815,
      "step": 1300
    },
    {
      "epoch": 9.44055944055944,
      "grad_norm": 1.1201107501983643,
      "learning_rate": 4.056643356643357e-05,
      "loss": 0.3799,
      "step": 1350
    },
    {
      "epoch": 9.79020979020979,
      "grad_norm": 1.4058353900909424,
      "learning_rate": 4.021678321678322e-05,
      "loss": 0.3765,
      "step": 1400
    },
    {
      "epoch": 10.13986013986014,
      "grad_norm": 1.0816528797149658,
      "learning_rate": 3.986713286713287e-05,
      "loss": 0.3729,
      "step": 1450
    },
    {
      "epoch": 10.48951048951049,
      "grad_norm": 1.2705639600753784,
      "learning_rate": 3.951748251748252e-05,
      "loss": 0.3734,
      "step": 1500
    },
    {
      "epoch": 10.83916083916084,
      "grad_norm": 2.236574649810791,
      "learning_rate": 3.916783216783217e-05,
      "loss": 0.3788,
      "step": 1550
    },
    {
      "epoch": 11.188811188811188,
      "grad_norm": 1.0591641664505005,
      "learning_rate": 3.881818181818182e-05,
      "loss": 0.3748,
      "step": 1600
    },
    {
      "epoch": 11.538461538461538,
      "grad_norm": 1.9529492855072021,
      "learning_rate": 3.846853146853147e-05,
      "loss": 0.3774,
      "step": 1650
    },
    {
      "epoch": 11.888111888111888,
      "grad_norm": 1.3004029989242554,
      "learning_rate": 3.811888111888112e-05,
      "loss": 0.3739,
      "step": 1700
    },
    {
      "epoch": 12.237762237762238,
      "grad_norm": 1.3133212327957153,
      "learning_rate": 3.7769230769230775e-05,
      "loss": 0.3688,
      "step": 1750
    },
    {
      "epoch": 12.587412587412587,
      "grad_norm": 1.1474148035049438,
      "learning_rate": 3.741958041958042e-05,
      "loss": 0.3731,
      "step": 1800
    },
    {
      "epoch": 12.937062937062937,
      "grad_norm": 1.1342874765396118,
      "learning_rate": 3.706993006993007e-05,
      "loss": 0.3728,
      "step": 1850
    },
    {
      "epoch": 13.286713286713287,
      "grad_norm": 1.6855899095535278,
      "learning_rate": 3.672027972027972e-05,
      "loss": 0.3692,
      "step": 1900
    },
    {
      "epoch": 13.636363636363637,
      "grad_norm": 1.301485300064087,
      "learning_rate": 3.637062937062937e-05,
      "loss": 0.3695,
      "step": 1950
    },
    {
      "epoch": 13.986013986013987,
      "grad_norm": 1.2360389232635498,
      "learning_rate": 3.602097902097902e-05,
      "loss": 0.3715,
      "step": 2000
    },
    {
      "epoch": 14.335664335664335,
      "grad_norm": 1.2910712957382202,
      "learning_rate": 3.5671328671328676e-05,
      "loss": 0.3705,
      "step": 2050
    },
    {
      "epoch": 14.685314685314685,
      "grad_norm": 1.5357187986373901,
      "learning_rate": 3.532167832167832e-05,
      "loss": 0.3696,
      "step": 2100
    },
    {
      "epoch": 15.034965034965035,
      "grad_norm": 1.314065933227539,
      "learning_rate": 3.497202797202798e-05,
      "loss": 0.3654,
      "step": 2150
    },
    {
      "epoch": 15.384615384615385,
      "grad_norm": 1.1589503288269043,
      "learning_rate": 3.4622377622377624e-05,
      "loss": 0.3711,
      "step": 2200
    },
    {
      "epoch": 15.734265734265735,
      "grad_norm": 1.2870415449142456,
      "learning_rate": 3.427272727272727e-05,
      "loss": 0.3671,
      "step": 2250
    },
    {
      "epoch": 16.083916083916083,
      "grad_norm": 1.586854338645935,
      "learning_rate": 3.3923076923076924e-05,
      "loss": 0.3671,
      "step": 2300
    },
    {
      "epoch": 16.433566433566433,
      "grad_norm": 1.2939438819885254,
      "learning_rate": 3.357342657342658e-05,
      "loss": 0.361,
      "step": 2350
    },
    {
      "epoch": 16.783216783216783,
      "grad_norm": 1.3646152019500732,
      "learning_rate": 3.3223776223776224e-05,
      "loss": 0.3678,
      "step": 2400
    },
    {
      "epoch": 17.132867132867133,
      "grad_norm": 1.406775951385498,
      "learning_rate": 3.287412587412588e-05,
      "loss": 0.3656,
      "step": 2450
    },
    {
      "epoch": 17.482517482517483,
      "grad_norm": 1.6645936965942383,
      "learning_rate": 3.252447552447553e-05,
      "loss": 0.3604,
      "step": 2500
    },
    {
      "epoch": 17.832167832167833,
      "grad_norm": 2.4611549377441406,
      "learning_rate": 3.217482517482517e-05,
      "loss": 0.3635,
      "step": 2550
    },
    {
      "epoch": 18.181818181818183,
      "grad_norm": 1.6051149368286133,
      "learning_rate": 3.1825174825174825e-05,
      "loss": 0.3654,
      "step": 2600
    },
    {
      "epoch": 18.53146853146853,
      "grad_norm": 1.6770615577697754,
      "learning_rate": 3.147552447552448e-05,
      "loss": 0.3619,
      "step": 2650
    },
    {
      "epoch": 18.88111888111888,
      "grad_norm": 1.315917730331421,
      "learning_rate": 3.1125874125874126e-05,
      "loss": 0.3639,
      "step": 2700
    },
    {
      "epoch": 19.23076923076923,
      "grad_norm": 1.634567379951477,
      "learning_rate": 3.077622377622378e-05,
      "loss": 0.3572,
      "step": 2750
    },
    {
      "epoch": 19.58041958041958,
      "grad_norm": 1.2998414039611816,
      "learning_rate": 3.042657342657343e-05,
      "loss": 0.3596,
      "step": 2800
    }
  ],
  "logging_steps": 50,
  "max_steps": 7150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 184278689316864.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
